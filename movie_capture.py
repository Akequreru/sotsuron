import cv2
import yt_dlp
import os
import random
import csv
import pickle
from datetime import timedelta
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request

# --- è¨­å®šã‚¨ãƒªã‚¢ ---
CLIENT_SECRET_FILE = 'credentials.json' 
SCOPES = ['https://www.googleapis.com/auth/drive.file']
COUNTER_FILE = 'last_index.txt'
CSV_FILE = 'captures_log.csv'
URL_LIST_FILE = 'urls.txt'
FOLDER_ID = '1qKmIlYTqYuXxwyu4_XzbF0b2exdlcutc'

# ã€é‡è¦ã€‘ã“ã“ã§æ­£é¢é¡”ã¨æ¨ªé¡”ã®åˆ†é¡å™¨ã‚’å®šç¾©ã—ã¾ã™ï¼ˆã‚¨ãƒ©ãƒ¼ã®ç›´æ¥ã®åŸå› ï¼‰
frontal_face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
profile_face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_profileface.xml')

RESOLUTIONS = [
    (256, 144), (426, 240), (640, 360), (854, 480), (1280, 720), (1920, 1080), (3840, 2160)
]

# --- Google Drive API é–¢é€£ ---

def get_drive_service():
    creds = None
    if os.path.exists('token.pickle'):
        with open('token.pickle', 'rb') as token:
            creds = pickle.load(token)
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file(CLIENT_SECRET_FILE, SCOPES)
            creds = flow.run_local_server(port=0)
        with open('token.pickle', 'wb') as token:
            pickle.dump(creds, token)
    return build('drive', 'v3', credentials=creds)

def upload_or_update_to_drive(file_name, mimetype='image/jpeg'):
    service = get_drive_service()
    query = f"name = '{file_name}' and trashed = false"
    if FOLDER_ID:
        query += f" and '{FOLDER_ID}' in parents"
    results = service.files().list(q=query, fields="files(id, name)").execute()
    items = results.get('files', [])
    media = MediaFileUpload(file_name, mimetype=mimetype, resumable=True)
    if items:
        file_id = items[0]['id']
        service.files().update(fileId=file_id, media_body=media).execute()
        print(f"  -> Driveæ›´æ–°å®Œäº†: {file_name}")
    else:
        file_metadata = {'name': file_name}
        if FOLDER_ID:
            file_metadata['parents'] = [FOLDER_ID]
        file = service.files().create(body=file_metadata, media_body=media, fields='id').execute()
        print(f"  -> Driveæ–°è¦ä¿å­˜: {file_name}")

# --- è£œåŠ©æ©Ÿèƒ½ ---

def format_time(seconds):
    return str(timedelta(seconds=int(seconds)))

def get_next_index():
    if os.path.exists(COUNTER_FILE):
        with open(COUNTER_FILE, 'r') as f:
            try: return int(f.read().strip())
            except: return 1
    return 1

def save_next_index(index):
    with open(COUNTER_FILE, 'w') as f:
        f.write(str(index))

def log_to_csv(title, url, timestamp, res_text):
    file_exists = os.path.isfile(CSV_FILE)
    with open(CSV_FILE, mode='a', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        if not file_exists:
            writer.writerow(['é¡Œå', 'URL', 'æ™‚é–“', 'è§£åƒåº¦'])
        writer.writerow([title, url, timestamp, res_text])

# --- å€‹åˆ¥å‹•ç”»ã®ã‚­ãƒ£ãƒ—ãƒãƒ£å‡¦ç† ---

def process_single_video(youtube_url):
    current_index = get_next_index()
    
    ydl_opts = {
        'format': 'bestvideo[height<=2160]', 
        'quiet': True,
        'no_warnings': True,
    }
    
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        try:
            info = ydl.extract_info(youtube_url, download=False)
            stream_url = None
            if 'formats' in info:
                formats = sorted(
                    info['formats'], 
                    key=lambda x: (x.get('height') if x.get('height') is not None else 0), 
                    reverse=True
                )
                for f in formats:
                    u = f.get('url', '')
                    if u and '.m3u8' not in u and f.get('vcodec') != 'none':
                        stream_url = u
                        break
            if not stream_url:
                stream_url = info.get('url')
            if not stream_url:
                raise Exception("ã‚¹ãƒˆãƒªãƒ¼ãƒ URLã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        except Exception as e:
            print(f"URLè§£æã‚¨ãƒ©ãƒ¼ ({youtube_url}): {e}")
            return current_index

    duration = info.get('duration', 0)
    title = info.get('title', 'Unknown Title')
    source_h = info.get('height', 0)

    print(f"\nğŸ¥ å‡¦ç†ä¸­: {title} (æœ€é«˜ç”»è³ª: {source_h}p)")
    
    cap = cv2.VideoCapture(stream_url, cv2.CAP_FFMPEG)
    if not cap.isOpened():
        print("ã‚¨ãƒ©ãƒ¼: å‹•ç”»ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸã€‚")
        return current_index

    current_time_sec = 60 if duration > 60 else duration // 2
    
    # å¼·åŒ–ã•ã‚ŒãŸé¡”èªè­˜é–¢æ•°
    def contains_face(frame_data):
        """æ­£é¢é¡”ã¾ãŸã¯æ¨ªé¡”ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ã™ã‚‹"""
        gray = cv2.cvtColor(frame_data, cv2.COLOR_BGR2GRAY)
        
        # å¾Œã‚å§¿ã‚’é¿ã‘ã‚‹ãŸã‚ã€minNeighbors ã‚’é«˜ã‚ï¼ˆ12ã€œ15ï¼‰ã«è¨­å®šã—ã¦ã„ã¾ã™
        # 1. æ­£é¢é¡”
        frontal_faces = frontal_face_cascade.detectMultiScale(
            gray, scaleFactor=1.1, minNeighbors=20, minSize=(50, 50)
        )
        if len(frontal_faces) > 0:
            return True

        # 2. æ¨ªé¡”ï¼ˆå³å‘ãï¼‰
        profile_faces = profile_face_cascade.detectMultiScale(
            gray, scaleFactor=1.1, minNeighbors=20, minSize=(50, 50)
        )
        if len(profile_faces) > 0:
            return True
            
        # 3. æ¨ªé¡”ï¼ˆå·¦å‘ãï¼šåè»¢ï¼‰
        gray_flipped = cv2.flip(gray, 1)
        profile_faces_flipped = profile_face_cascade.detectMultiScale(
            gray_flipped, scaleFactor=1.1, minNeighbors=20, minSize=(50, 50)
        )
        if len(profile_faces_flipped) > 0:
            return True
            
        return False

    def save_and_cleanup(frame_data, time_str, index):
        if not contains_face(frame_data):
            print(f"  [Skip] é¡”ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ ({time_str})")
            return index

        actual_h, actual_w, _ = frame_data.shape
        valid_res = [res for res in RESOLUTIONS if res[1] <= actual_h]
        
        if actual_h >= 2160:
            target_res = (actual_w, actual_h) if random.random() < 0.5 else random.choice(valid_res)
        else:
            target_res = random.choice(valid_res) if valid_res else (actual_w, actual_h)

        final_frame = cv2.resize(frame_data, (target_res[0], target_res[1]), interpolation=cv2.INTER_AREA)
        file_name = f"not_glitch_image_{index:05d}.jpg"
        cv2.imwrite(file_name, final_frame)
        
        log_to_csv(title, youtube_url, time_str, f"{target_res[1]}p")
        upload_or_update_to_drive(file_name)
        
        print(f"  -> ä¿å­˜å®Œäº†: {target_res[1]}p (ãƒ‡ã‚³ãƒ¼ãƒ‰å…ƒ: {actual_h}p)")
        if os.path.exists(file_name):
            os.remove(file_name)
        
        return index + 1

    # --- ã‚­ãƒ£ãƒ—ãƒãƒ£ãƒ«ãƒ¼ãƒ—ï¼ˆ30-90ç§’é–“éš”ï¼‰ ---
    while current_time_sec < duration:
        cap.set(cv2.CAP_PROP_POS_MSEC, current_time_sec * 1000)
        success, frame = cap.read()
        
        if success:
            timestamp = format_time(current_time_sec)
            print(f"[{timestamp}] ã‚¹ã‚­ãƒ£ãƒ³ä¸­...")
            new_index = save_and_cleanup(frame, timestamp, current_index)
            
            if new_index > current_index:
                current_index = new_index
                save_next_index(current_index)
        else:
            print(f"[{format_time(current_time_sec)}] ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—å¤±æ•—")

        interval = random.randint(60, 120)
        current_time_sec += interval

    cap.release()
    return current_index

def main():
    if not os.path.exists(URL_LIST_FILE):
        print(f"ã‚¨ãƒ©ãƒ¼: {URL_LIST_FILE} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return
    with open(URL_LIST_FILE, 'r') as f:
        urls = [line.strip() for line in f if line.strip()]

    print(f"åˆè¨ˆ {len(urls)} æœ¬ã®å‹•ç”»ã‚’å‡¦ç†ã—ã¾ã™ã€‚")
    for i, url in enumerate(urls, 1):
        print(f"\n--- é€²æ—: {i}/{len(urls)} ---")
        try:
            process_single_video(url)
            upload_or_update_to_drive(CSV_FILE, mimetype='text/csv')
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            continue
    print("\nâœ¨ ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    main()